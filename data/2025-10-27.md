<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 12]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [AgentArcEval: An Architecture Evaluation Method for Foundation Model based Agents](https://arxiv.org/abs/2510.21031)
*Qinghua Lu,Dehai Zhao,Yue Liu,Hao Zhang,Liming Zhu,Xiwei Xu,Angela Shi,Tristan Tan,Rick Kazman*

Main category: cs.SE

TL;DR: AgentArcEval is a novel method for evaluating foundation model-based agent architectures, addressing their unique characteristics like compound structure and autonomous behavior, with a case study on a tax copilot system.


<details>
  <summary>Details</summary>
Motivation: Traditional evaluation methods are insufficient for FM-based agent architectures due to their unique characteristics including compound architecture, autonomous/non-deterministic behavior, and continuous evolution.

Method: Proposes AgentArcEval, a specialized evaluation method for FM-based agent architectures, along with a catalogue of agent-specific general scenarios to guide concrete scenario generation.

Result: Demonstrated through a case study on Luna, a real-world tax copilot system, showing the method's usefulness in evaluating agent architecture.

Conclusion: AgentArcEval effectively addresses the evaluation needs of foundation model-based agent architectures, providing a specialized approach that traditional methods cannot handle.

Abstract: The emergence of foundation models (FMs) has enabled the development of
highly capable and autonomous agents, unlocking new application opportunities
across a wide range of domains. Evaluating the architecture of agents is
particularly important as the architectural decisions significantly impact the
quality attributes of agents given their unique characteristics, including
compound architecture, autonomous and non-deterministic behaviour, and
continuous evolution. However, these traditional methods fall short in
addressing the evaluation needs of agent architecture due to the unique
characteristics of these agents. Therefore, in this paper, we present
AgentArcEval, a novel agent architecture evaluation method designed specially
to address the complexities of FM-based agent architecture and its evaluation.
Moreover, we present a catalogue of agent-specific general scenarios, which
serves as a guide for generating concrete scenarios to design and evaluate the
agent architecture. We demonstrate the usefulness of AgentArcEval and the
catalogue through a case study on the architecture evaluation of a real-world
tax copilot, named Luna.

</details>


### [2] [BDiff: Block-aware and Accurate Text-based Code Differencing](https://arxiv.org/abs/2510.21094)
*Yao Lu,Wanwei Liu,Tanghaoran Zhang,Kang Yang,Yang Zhang,Wenyu Xu,Longfei Sun,Xinjun Mao,Shuzheng Gao,Michael R. Lyu*

Main category: cs.SE

TL;DR: BDiff is a text-based code differencing algorithm that identifies block-level and line-level edit actions, outperforming existing tools including LLMs in result quality while maintaining competitive runtime.


<details>
  <summary>Details</summary>
Motivation: Existing code differencing tools fail to properly identify block-level edit actions (like moving or duplicating multi-line code blocks), representing them as discrete line-level changes that developers must manually correlate, which hinders change comprehension efficiency.

Method: BDiff builds on traditional differencing algorithms by constructing candidate sets of line and block mappings, then uses the Kuhn-Munkres algorithm to compute optimal mappings that minimize edit script size while aligning with developer intent.

Result: BDiff produces higher-quality differencing results than five state-of-the-art baseline tools (including LLMs), maintaining competitive runtime performance. LLMs proved unreliable in result quality and infeasible in runtime efficiency.

Conclusion: BDiff effectively addresses the limitation of existing tools in identifying block-level edit actions, providing more accurate and developer-friendly code differencing results, with a web-based visual tool implementation available.

Abstract: Code differencing is a fundamental technique in software engineering practice
and research. While researchers have proposed text-based differencing
techniques capable of identifying line changes over the past decade, existing
methods exhibit a notable limitation in identifying edit actions (EAs) that
operate on text blocks spanning multiple lines. Such EAs are common in
developers' practice, such as moving a code block for conditional branching or
duplicating a method definition block for overloading. Existing tools represent
such block-level operations as discrete sequences of line-level EAs, compelling
developers to manually correlate them and thereby substantially impeding the
efficiency of change comprehension. To address this issue, we propose BDiff, a
text-based differencing algorithm capable of identifying two types of
block-level EAs and five types of line-level EAs. Building on traditional
differencing algorithms, we first construct a candidate set containing all
possible line mappings and block mappings. Leveraging the Kuhn-Munkres
algorithm, we then compute the optimal mapping set that can minimize the size
of the edit script (ES) while closely aligning with the original developer's
intent. To validate the effectiveness of BDiff, we selected five
state-of-the-art tools, including large language models (LLMs), as baselines
and adopted a combined qualitative and quantitative approach to evaluate their
performance in terms of ES size, result quality, and running time. Experimental
results show that BDiff produces higher-quality differencing results than
baseline tools while maintaining competitive runtime performance. Our
experiments also show the unreliability of LLMs in code differencing tasks
regarding result quality and their infeasibility in terms of runtime
efficiency. We have implemented a web-based visual differencing tool.

</details>


### [3] [R2ComSync: Improving Code-Comment Synchronization with In-Context Learning and Reranking](https://arxiv.org/abs/2510.21106)
*Zhen Yang,Hongyi Lin,Xiao Yu,Jacky Wai Keung,Shuo Liu,Pak Yuen Patrick Chan,Yicheng Sun,Fengji Zhang*

Main category: cs.SE

TL;DR: R2ComSync is a novel code-comment synchronization approach that uses retrieval-augmented in-context learning and multi-turn re-ranking to improve LLM performance in synchronizing comments with code changes.


<details>
  <summary>Details</summary>
Motivation: Previous code-comment synchronization approaches lack generalization ability and require extensive task-specific resources. LLMs show potential but underperform SOTA methods due to lack of instructive demonstrations and poor candidate prioritization.

Method: R2ComSync uses ensemble hybrid retrieval (considering both code-comment semantics and change patterns) to create effective ICL prompts, and a multi-turn re-ranking strategy with three derived rules to prioritize correct-prone candidates from LLM outputs.

Result: Evaluation on three datasets covering Java and Python shows R2ComSync outperforms five SOTA approaches. Both quantitative and qualitative analyses demonstrate significantly higher quality synchronized comments.

Conclusion: R2ComSync successfully addresses LLM limitations in code-comment synchronization through retrieval-augmented ICL and intelligent re-ranking, achieving superior performance over existing methods.

Abstract: Code-Comment Synchronization (CCS) aims to synchronize the comments with code
changes in an automated fashion, thereby significantly reducing the workload of
developers during software maintenance and evolution. While previous studies
have proposed various solutions that have shown success, they often exhibit
limitations, such as a lack of generalization ability or the need for extensive
task-specific learning resources. This motivates us to investigate the
potential of Large Language Models (LLMs) in this area. However, a pilot
analysis proves that LLMs fall short of State-Of-The-Art (SOTA) CCS approaches
because (1) they lack instructive demonstrations for In-Context Learning (ICL)
and (2) many correct-prone candidates are not prioritized.To tackle the above
challenges, we propose R2ComSync, an ICL-based code-Comment Synchronization
approach enhanced with Retrieval and Re-ranking. Specifically, R2ComSync
carries corresponding two novelties: (1) Ensemble hybrid retrieval. It equally
considers the similarity in both code-comment semantics and change patterns
when retrieval, thereby creating ICL prompts with effective examples. (2)
Multi-turn re-ranking strategy. We derived three significant rules through
large-scale CCS sample analysis. Given the inference results of LLMs, it
progressively exploits three re-ranking rules to prioritize relatively
correct-prone candidates. We evaluate R2ComSync using five recent LLMs on three
CCS datasets covering both Java and Python programming languages, and make
comparisons with five SOTA approaches. Extensive experiments demonstrate the
superior performance of R2ComSync against other approaches. Moreover, both
quantitative and qualitative analyses provide compelling evidence that the
comments synchronized by our proposal exhibit significantly higher quality.}

</details>


### [4] [GreenMalloc: Allocator Optimisation for Industrial Workloads](https://arxiv.org/abs/2510.21405)
*Aidan Dakhama,W. B. Langdon,Hector D. Menendez,Karine Even-Mendoza*

Main category: cs.SE

TL;DR: GreenMalloc is a search-based framework that automatically configures memory allocators using NSGA-II and rand_malloc to optimize heap usage while maintaining runtime efficiency.


<details>
  <summary>Details</summary>
Motivation: To automatically optimize memory allocator configurations for reduced heap usage without sacrificing performance, addressing the complexity of manual tuning.

Method: Uses NSGA-II multi-objective search algorithm with rand_malloc as a lightweight proxy benchmark, analyzes execution traces, and transfers best configurations to gem5 simulator for validation on glibc malloc and TCMalloc.

Result: Achieved up to 4.1% reduction in average heap usage with no runtime efficiency loss; actually achieved 0.25% improvement in runtime efficiency.

Conclusion: GreenMalloc successfully demonstrates automated memory allocator configuration can significantly reduce heap usage while maintaining or slightly improving runtime performance across diverse workloads.

Abstract: We present GreenMalloc, a multi objective search-based framework for
automatically configuring memory allocators. Our approach uses NSGA II and
rand_malloc as a lightweight proxy benchmarking tool. We efficiently explore
allocator parameters from execution traces and transfer the best configurations
to gem5, a large system simulator, in a case study on two allocators: the GNU
C/CPP compiler's glibc malloc and Google's TCMalloc. Across diverse workloads,
our empirical results show up to 4.1 percantage reduction in average heap usage
without loss of runtime efficiency; indeed, we get a 0.25 percantage reduction.

</details>


### [5] [Context Engineering for AI Agents in Open-Source Software](https://arxiv.org/abs/2510.21413)
*Seyedmoein Mohsenimofidi,Matthias Galster,Christoph Treude,Sebastian Baltes*

Main category: cs.SE

TL;DR: This paper analyzes the adoption and evolution of AGENTS.md files in 466 open-source projects, finding no established structure yet and significant variation in how context is provided to AI coding assistants.


<details>
  <summary>Details</summary>
Motivation: As AI agents become more autonomous in software development, they need contextual information about projects. AGENTS.md has emerged as a potential standard for providing this context, but little is known about actual developer adoption patterns.

Method: Conducted a preliminary study analyzing 466 open-source software projects to investigate adoption of AI configuration files, examining what information developers provide, how they present it, and how these files evolve over time.

Result: Findings show no established structure for AGENTS.md files yet, with significant variation in how context is provided (descriptive, prescriptive, prohibitive, explanatory, conditional). Analysis of commit history reveals how projects continuously extend and maintain these files.

Conclusion: The adoption of AI configuration files provides a unique opportunity to study real-world prompt and context engineering, with potential to investigate how modifications in structure or presentation affect the quality of AI-generated content.

Abstract: GenAI-based coding assistants have disrupted software development. Their next
generation is agent-based, operating with more autonomy and potentially without
human oversight. One challenge is to provide AI agents with sufficient context
about the software projects they operate in. Like humans, AI agents require
contextual information to develop solutions that are in line with the target
architecture, interface specifications, coding guidelines, standard workflows,
and other project-specific policies. Popular AI agents for software development
(e.g., Claude Code) advocate for maintaining tool-specific version-controlled
Markdown files that cover aspects such as the project structure, building and
testing, or code style. The content of these files is automatically added to
each prompt. AGENTS.md has emerged as a potential standard that consolidates
tool-specific formats. However, little is known about whether and how
developers adopt this format. Therefore, in this paper, we present the results
of a preliminary study investigating the adoption of AI configuration files in
466 open-source software projects, what information developers provide in these
files, how they present that information, and how they evolve over time. Our
findings indicate that there is no established structure yet, and that there is
a lot of variation in terms of how context is provided (descriptive,
prescriptive, prohibitive, explanatory, conditional). We see great potential in
studying which modifications in structure or presentation can positively affect
the quality of the generated content. Finally, our analysis of commits that
have modified AGENTS.md files provides first insights into how projects
continuously extend and maintain these files. We conclude the paper by
outlining how the adoption of AI configuration files in provides a unique
opportunity to study real-world prompt and context engineering.

</details>


### [6] [Does Model Size Matter? A Comparison of Small and Large Language Models for Requirements Classification](https://arxiv.org/abs/2510.21443)
*Mohammad Amin Zadenoori,Vincenzo De Martino,Jacek Dabrowski,Xavier Franch,Alessio Ferrari*

Main category: cs.SE

TL;DR: SLMs perform nearly as well as LLMs in requirements classification tasks despite being much smaller, with no statistically significant performance difference.


<details>
  <summary>Details</summary>
Motivation: LLMs have computational costs, data sharing risks, and external service dependencies, while SLMs offer lightweight, locally deployable alternatives.

Method: Compared 8 models (3 LLMs, 5 SLMs) on requirements classification using PROMISE, PROMISE Reclass, and SecReq datasets.

Result: LLMs achieved only 2% higher average F1 score than SLMs (not statistically significant). SLMs even outperformed LLMs in recall on PROMISE Reclass dataset despite being up to 300x smaller.

Conclusion: SLMs are a valid alternative to LLMs for requirements classification, offering advantages in privacy, cost, and local deployability.

Abstract: [Context and motivation] Large language models (LLMs) show notable results in
natural language processing (NLP) tasks for requirements engineering (RE).
However, their use is compromised by high computational cost, data sharing
risks, and dependence on external services. In contrast, small language models
(SLMs) offer a lightweight, locally deployable alternative. [Question/problem]
It remains unclear how well SLMs perform compared to LLMs in RE tasks in terms
of accuracy. [Results] Our preliminary study compares eight models, including
three LLMs and five SLMs, on requirements classification tasks using the
PROMISE, PROMISE Reclass, and SecReq datasets. Our results show that although
LLMs achieve an average F1 score of 2% higher than SLMs, this difference is not
statistically significant. SLMs almost reach LLMs performance across all
datasets and even outperform them in recall on the PROMISE Reclass dataset,
despite being up to 300 times smaller. We also found that dataset
characteristics play a more significant role in performance than model size.
[Contribution] Our study contributes with evidence that SLMs are a valid
alternative to LLMs for requirements classification, offering advantages in
privacy, cost, and local deployability.

</details>


### [7] [Scalpel: Automotive Deep Learning Framework Testing via Assembling Model Components](https://arxiv.org/abs/2510.21451)
*Yinglong Zou,Juan Zhai,Chunrong Fang,An Guo,Jiawei Liu,Zhenyu Chen*

Main category: cs.SE

TL;DR: Scalpel is a testing method for automotive DL frameworks that generates test models by assembling components (heads, necks, backbones) to address unique quality issues in autonomous driving systems.


<details>
  <summary>Details</summary>
Motivation: Existing DL framework testing methods fail to detect quality issues in automotive systems due to inability to generate models with essential capabilities: multi-input/output tensor processing, multi-modal data processing, and multi-level data feature extraction.

Method: Scalpel generates test models at component level by maintaining a repository of model components, selecting, mutating, and assembling them to create models with required capabilities, then using differential testing.

Result: The method successfully generates deployable test models that can detect quality issues in automotive DL frameworks that existing methods miss.

Conclusion: Scalpel bridges the gap in automotive DL framework testing by generating specialized test models through component assembly, enabling detection of unique quality issues in autonomous driving deployment environments.

Abstract: Deep learning (DL) plays a key role in autonomous driving systems. DL models
support perception modules, equipped with tasks such as object detection and
sensor fusion. These DL models enable vehicles to process multi-sensor inputs
to understand complex surroundings. Deploying DL models in autonomous driving
systems faces stringent challenges, including real-time processing, limited
computational resources, and strict power constraints. To address these
challenges, automotive DL frameworks (e.g., PaddleInference) have emerged to
optimize inference efficiency. However, these frameworks encounter unique
quality issues due to their more complex deployment environments, such as
crashes stemming from limited scheduled memory and incorrect memory allocation.
Unfortunately, existing DL framework testing methods fail to detect these
quality issues due to the failure in deploying generated test input models, as
these models lack three essential capabilities: (1) multi-input/output tensor
processing, (2) multi-modal data processing, and (3) multi-level data feature
extraction. These capabilities necessitate specialized model components, which
existing testing methods neglect during model generation. To bridge this gap,
we propose Scalpel, an automotive DL frameworks testing method that generates
test input models at the model component level. Scalpel generates models by
assembling model components (heads, necks, backbones) to support capabilities
required by autonomous driving systems. Specifically, Scalpel maintains and
updates a repository of model components, generating test inputs by selecting,
mutating, and assembling them. Successfully generated models are added back to
enrich the repository. Newly generated models are then deployed within the
autonomous driving system to test automotive DL frameworks via differential
testing.

</details>


### [8] [Towards Socio-Technical Topology-Aware Adaptive Threat Detection in Software Supply Chains](https://arxiv.org/abs/2510.21452)
*Thomas Welsh,Kristófer Finnsson,Brynjólfur Stefánsson,Helmut Neukirchen*

Main category: cs.SE

TL;DR: The paper proposes using socio-technical models for adaptive threat detection in software supply chains, motivated by the XZ Utils attack, and identifies research challenges.


<details>
  <summary>Details</summary>
Motivation: Software supply chains are complex and vulnerable to attacks, but current approaches focus mainly on technical monitoring without considering socio-technical dynamics, as demonstrated by the XZ Utils attack where malicious actors exploited social trust mechanisms.

Method: The paper outlines a research vision to develop socio-technical models that monitor both technical and social data to identify suspicious behavior patterns, enabling targeted vulnerability assessment.

Result: The analysis shows that monitoring socio-technical dynamics can reveal trends indicating malicious activity, allowing for more effective threat detection in complex software supply chains.

Conclusion: There is a need for research into socio-technical modeling for adaptive threat detection, with key challenges including developer/software analysis techniques, decentralized adaptation, and creating testbeds for supply chain security research.

Abstract: Software supply chains (SSCs) are complex systems composed of dynamic,
heterogeneous technical and social components which collectively achieve the
production and maintenance of software artefacts. Attacks on SSCs are
increasing, yet pervasive vulnerability analysis is challenging due to their
complexity. Therefore, threat detection must be targeted, to account for the
large and dynamic structure, and adaptive, to account for its change and
diversity. While current work focuses on technical approaches for monitoring
supply chain dependencies and establishing component controls, approaches which
inform threat detection through understanding the socio-technical dynamics are
lacking. We outline a position and research vision to develop and investigate
the use of socio-technical models to support adaptive threat detection of SSCs.
We motivate this approach through an analysis of the XZ Utils attack whereby
malicious actors undermined the maintainers' trust via the project's GitHub and
mailing lists. We highlight that monitoring technical and social data can
identify trends which indicate suspicious behaviour to then inform targeted and
intensive vulnerability assessment. We identify challenges and research
directions to achieve this vision considering techniques for developer and
software analysis, decentralised adaptation and the need for a test bed for
software supply chain security research.

</details>


### [9] [Risk Management for Mitigating Benchmark Failure Modes: BenchRisk](https://arxiv.org/abs/2510.21460)
*Sean McGregor,Victor Lu,Vassil Tashev,Armstrong Foundjem,Aishwarya Ramasethu,Sadegh AlMahdi Kazemi Zarkouei,Chris Knotz,Kongtao Chen,Alicia Parrish,Anka Reuel,Heather Frase*

Main category: cs.SE

TL;DR: This paper introduces BenchRisk, a metaevaluation framework that identifies 57 potential failure modes in LLM benchmarks and provides 196 mitigation strategies to assess benchmark reliability and reduce the risk of incorrect conclusions about LLMs.


<details>
  <summary>Details</summary>
Motivation: LLM benchmarks are crucial for deployment decisions but can be unreliable due to various failure modes affecting bias, variance, coverage, and interpretability, potentially leading to incorrect conclusions about LLM safety and capabilities.

Method: Used NIST's risk management process to analyze 26 popular benchmarks, identifying failure modes and mitigation strategies. Developed BenchRisk scoring system across five dimensions: comprehensiveness, intelligibility, consistency, correctness, and longevity.

Result: All 26 benchmarks showed significant risk in at least one dimension. BenchRisk provides a systematic way to compare benchmarks and identify areas needing improvement in LLM benchmarking practices.

Conclusion: Current LLM benchmarks have substantial reliability issues across multiple dimensions. BenchRisk offers a practical framework for evaluating benchmark quality and highlights important research directions for improving LLM benchmarking standards.

Abstract: Large language model (LLM) benchmarks inform LLM use decisions (e.g., "is
this LLM safe to deploy for my use case and context?"). However, benchmarks may
be rendered unreliable by various failure modes that impact benchmark bias,
variance, coverage, or people's capacity to understand benchmark evidence.
Using the National Institute of Standards and Technology's risk management
process as a foundation, this research iteratively analyzed 26 popular
benchmarks, identifying 57 potential failure modes and 196 corresponding
mitigation strategies. The mitigations reduce failure likelihood and/or
severity, providing a frame for evaluating "benchmark risk," which is scored to
provide a metaevaluation benchmark: BenchRisk. Higher scores indicate that
benchmark users are less likely to reach an incorrect or unsupported conclusion
about an LLM. All 26 scored benchmarks present significant risk within one or
more of the five scored dimensions (comprehensiveness, intelligibility,
consistency, correctness, and longevity), which points to important open
research directions for the field of LLM benchmarking. The BenchRisk workflow
allows for comparison between benchmarks; as an open-source tool, it also
facilitates the identification and sharing of risks and their mitigations.

</details>


### [10] [Wisdom and Delusion of LLM Ensembles for Code Generation and Repair](https://arxiv.org/abs/2510.21513)
*Fernando Vallecillos Ruiz,Max Hort,Leon Moonen*

Main category: cs.SE

TL;DR: Ensembles of coding LLMs can achieve 83% higher performance than single models, but consensus-based strategies fall into 'popularity traps' while diversity-based strategies realize up to 95% of this potential.


<details>
  <summary>Details</summary>
Motivation: Current pursuit of single Large Language Models for software engineering is resource-intensive and overlooks complementarity benefits between different models, but the best ensemble strategies remain unclear.

Method: Empirically compared 10 individual LLMs from 5 families and 3 ensembles across 3 software engineering benchmarks covering code generation and program repair, evaluating complementarity and solution selection heuristics.

Result: Theoretical upperbound for ensemble performance is 83% above best single model. Diversity-based strategies achieve up to 95% of this potential, while consensus-based strategies amplify common but incorrect outputs.

Conclusion: Diversity-based ensemble strategies enable cost-efficient performance enhancement by leveraging multiple LLMs, proving effective even in small two-model ensembles.

Abstract: Today's pursuit of a single Large Language Model (LMM) for all software
engineering tasks is resource-intensive and overlooks the potential benefits of
complementarity, where different models contribute unique strengths. However,
the degree to which coding LLMs complement each other and the best strategy for
maximizing an ensemble's potential are unclear, leaving practitioners without a
clear path to move beyond single-model systems.
  To address this gap, we empirically compare ten individual LLMs from five
families, and three ensembles of these LLMs across three software engineering
benchmarks covering code generation and program repair. We assess the
complementarity between models and the performance gap between the best
individual model and the ensembles. Next, we evaluate various selection
heuristics to identify correct solutions from an ensemble's candidate pool.
  We find that the theoretical upperbound for an ensemble's performance can be
83% above the best single model. Our results show that consensus-based
strategies for selecting solutions fall into a "popularity trap," amplifying
common but incorrect outputs. In contrast, a diversity-based strategy realizes
up to 95% of this theoretical potential, and proves effective even in small
two-model ensembles, enabling a cost-efficient way to enhance performance by
leveraging multiple LLMs.

</details>


### [11] [Lights-Out: An Automated Ground Segment for unstaffed Satellite Operations](https://arxiv.org/abs/2510.21516)
*Marvin Böcker,Ralph Biggins,Michael Schmeing*

Main category: cs.SE

TL;DR: A fully automated ground segment system for the Heinrich Hertz satellite mission that enables unstaffed operations through automated scheduling, monitoring, and user self-service capabilities.


<details>
  <summary>Details</summary>
Motivation: To enable periodically unstaffed, fully automated satellite operations for the Heinrich Hertz mission, allowing flexible 24/7 access for users while reducing human intervention requirements.

Method: Implemented major automation concepts including automated TTC (tracking, telemetry, commanding), pre-planned schedules, automatic monitoring with configurable reactions, and a self-service user portal for experiment scheduling and monitoring.

Result: Successfully deployed for the Heinrich Hertz satellite launched in July 2023, enabling fully automated operations outside office hours with flexible user access and rapid reconfiguration capabilities (less than 1 minute reaction time).

Conclusion: The automated ground segment concept successfully demonstrates that satellite operations can be conducted with minimal human intervention while providing flexible 24/7 access to users through self-service capabilities and rapid response mechanisms.

Abstract: We present our approach for a periodically unstaffed, fully automated ground
segment. The concept is in use for the first time on the German satellite
communications mission Heinrich Hertz on behalf of the German Space Agency at
DLR. Heinrich Hertz was launched in July 2023 and offers access to scientific
and technical experiments to its users. The mission utilizes major automation
concepts for the satellite platform operations, allowing fully automated
operations outside of office hours. The concept includes tracking, telemetry
and commanding (TTC) of the satellite. Pre-planned and automatically executed
schedules enable commanding without human interaction. The user mission
schedule is planned separately from the main mission schedule and is
automatically de-conflicted. The automatic monitoring concept monitors the
systems of the satellite and all assets in the ground segment and triggers
reactions in operator-configurable ways depending on the mission needs, for
example emergency notifications or automated execution of flight operation
procedures. Additionally, the concept also puts special emphasis on a
self-service user portal that provides flexible access 24/7, even when the
control center is not staffed. The portal allows external users of the payload
to schedule pre-defined experiments, monitor the live execution of the
experiment with browser-based displays and access ground station telemetry and
dedicated RF test equipment during the time of their scheduled experiment.
Tasks can be planned long in advance as well as with a short reaction time
(less than 1 minute), which allows, for example, the reconfiguration of the
payload during a running experiment.

</details>


### [12] [Privacy by Design: Aligning GDPR and Software Engineering Specifications with a Requirements Engineering Approach](https://arxiv.org/abs/2510.21591)
*Oleksandr Kosenkov,Ehsan Zabardast,Davide Fucci,Daniel Mendez,Michael Unterkalmsteiner*

Main category: cs.SE

TL;DR: This paper presents an approach for conjoint requirements and system specification to address GDPR compliance through privacy by design, focusing on capturing legal knowledge and supporting traceability.


<details>
  <summary>Details</summary>
Motivation: There is limited understanding of practitioners' perspectives on specification objectives for privacy by design, and existing approaches don't adequately address the complex intersection between problem and solution space in GDPR.

Method: Conducted literature review and practitioner interviews to understand state-of-practice and specification objectives, then developed and evaluated an approach for requirements and systems specification for PbD.

Result: The approach successfully captures legal knowledge from GDPR text, supports specification transparency and traceability, and addresses the relationship between problem and solution space essential for PbD.

Conclusion: GDPR demands must be addressed throughout engineering lifecycle levels of abstraction, and legal knowledge from GDPR text should be captured in specifications to ensure compliance and meet stakeholder needs.

Abstract: Context: Consistent requirements and system specifications are essential for
the compliance of software systems towards the General Data Protection
Regulation (GDPR). Both artefacts need to be grounded in the original text and
conjointly assure the achievement of privacy by design (PbD). Objectives: There
is little understanding of the perspectives of practitioners on specification
objectives and goals to address PbD. Existing approaches do not account for the
complex intersection between problem and solution space expressed in GDPR. In
this study we explore the demand for conjoint requirements and system
specification for PbD and suggest an approach to address this demand. Methods:
We reviewed secondary and related primary studies and conducted interviews with
practitioners to (1) investigate the state-of-practice and (2) understand the
underlying specification objectives and goals (e.g., traceability). We
developed and evaluated an approach for requirements and systems specification
for PbD, and evaluated it against the specification objectives. Results: The
relationship between problem and solution space, as expressed in GDPR, is
instrumental in supporting PbD. We demonstrate how our approach, based on the
modeling GDPR content with original legal concepts, contributes to
specification objectives of capturing legal knowledge, supporting specification
transparency, and traceability. Conclusion: GDPR demands need to be addressed
throughout different levels of abstraction in the engineering lifecycle to
achieve PbD. Legal knowledge specified in the GDPR text should be captured in
specifications to address the demands of different stakeholders and ensure
compliance. While our results confirm the suitability of our approach to
address practical needs, we also revealed specific needs for the future
effective operationalization of the approach.

</details>
