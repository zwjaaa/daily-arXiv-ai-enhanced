<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 28]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [PBFD and PDFD: Formally Defined and Verified Methodologies and Empirical Evaluation for Scalable Full-Stack Software Engineering](https://arxiv.org/abs/2510.00002)
*Dong Liu*

Main category: cs.SE

TL;DR: PBFD and PDFD are formal methodologies for scalable full-stack software engineering that bridge formal methods with real-world practice using graph-theoretic modeling and CSP verification.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between formal methods and real-world development practice by providing scalable, industrial-grade approaches with structural correctness guarantees.

Method: Uses layered directed graphs formalized with unified state machines and CSP, plus Three-Level Encapsulation (TLE) for constant-time hierarchical data coordination.

Result: Empirical validation showed 20x faster development than Salesforce OmniScript and 7-8x faster query performance than conventional relational models in an 8-year enterprise deployment.

Conclusion: PBFD and PDFD establish a reproducible framework integrating formal verification into practical software development, with open-source implementations available for adoption.

Abstract: This paper introduces Primary Breadth-First Development (PBFD) and Primary
Depth-First Development (PDFD), two formally defined and verified methodologies
for scalable, industrial-grade full-stack software engineering. These
approaches bridge a longstanding gap between formal methods and real-world
development practice by enforcing structural correctness through
graph-theoretic modeling. Unlike prior graph-based approaches, PBFD and PDFD
operate over layered directed graphs and are formalized using unified state
machines and Communicating Sequential Processes (CSP) to ensure critical
properties, including bounded-refinement termination and structural
completeness. To coordinate hierarchical data at scale, we propose Three-Level
Encapsulation (TLE) - a novel, bitmask-based encoding scheme that delivers
provably constant-time updates. TLE's formal guarantees underpin PBFD's
industrial-scale performance and scalability. PBFD was empirically validated
through an eight-year enterprise deployment, demonstrating over 20x faster
development than Salesforce OmniScript and 7-8x faster query performance
compared to conventional relational models. Additionally, both methodologies
are supported by open-source MVPs, with PDFD's implementation conclusively
demonstrating its correctness-first design principles. Together, PBFD and PDFD
establish a reproducible, transparent framework that integrates formal
verification into practical software development. All formal specifications,
MVPs, and datasets are publicly available to foster academic research and
industrial-grade adoption.

</details>


### [2] [Semantic Zoom and Mini-Maps for Software Cities](https://arxiv.org/abs/2510.00003)
*Malte Hansen,Jens Bamberg,Noe Baumann,Wilhelm Hasselbring*

Main category: cs.SE

TL;DR: This paper presents semantic zoom and mini-map approaches to improve visual scalability in 3D software cities, implemented in the ExplorViz tool and evaluated through user studies.


<details>
  <summary>Details</summary>
Motivation: Software visualizations can become difficult to comprehend as the amount of displayed data increases, creating a visual scalability problem in 3D software cities.

Method: Two approaches: semantic zoom (changing graphical representation based on camera distance) and mini-map (2D top-view projection), implemented in the web-based ExplorViz tool for live trace visualization.

Result: User studies showed both approaches are useful additions, especially for large software landscapes and collaborative exploration, with good usability but some implementation shortcomings identified.

Conclusion: Semantic zoom and mini-maps effectively address visual scalability challenges in 3D software visualizations, though future work is needed to address implementation limitations.

Abstract: Software visualization tools can facilitate program comprehension by
providing visual metaphors, or abstractions that reduce the amount of textual
data that needs to be processed mentally. One way they do this is by enabling
developers to build an internal representation of the visualized software and
its architecture. However, as the amount of displayed data in the visualization
increases, the visualization itself can become more difficult to comprehend.
The ability to display small and large amounts of data in visualizations is
called visual scalability.
  In this paper, we present two approaches to address the challenge of visual
scalability in 3D software cities. First, we present an approach to semantic
zoom, in which the graphical representation of the software landscape changes
based on the virtual camera's distance from visual objects. Second, we augment
the visualization with a miniature two-dimensional top-view projection called
mini-map. We demonstrate our approach using an open-source implementation in
our software visualization tool ExplorViz. ExplorViz is web-based and uses the
3D city metaphor, focusing on live trace visualization.
  We evaluated our approaches in two separate user studies. The results
indicate that semantic zoom and the mini-map are both useful additions. User
feedback indicates that semantic zoom and mini-maps are especially useful for
large software landscapes and collaborative software exploration. The studies
indicate a good usability of our implemented approaches. However, some
shortcomings in our implementations have also been discovered, to be addressed
in future work.
  Video URL: https://youtu.be/LYtUeWvizjU

</details>


### [3] [HTML Structure Exploration in 3D Software Cities](https://arxiv.org/abs/2510.00004)
*Malte Hansen,David Moreno-Lumbreras,Wilhelm Hasselbring*

Main category: cs.SE

TL;DR: This paper introduces a web-based software visualization tool called ExplorViz that embeds web views and visualizes the Document Object Model (DOM) in 3D to help understand web interface behavior in software systems.


<details>
  <summary>Details</summary>
Motivation: Large software systems often have web interfaces that are not adequately represented in existing software visualization tools, making it difficult to explore and understand their behavior.

Method: The authors extended ExplorViz by adding an embedded web view for instrumented applications and created a 3D visualization of the HTML structure (DOM) in same-origin contexts.

Result: A preliminary user study was conducted, providing insights into potential use cases, benefits, and shortcomings of the approach.

Conclusion: The study results suggest directions for further research to support visual exploration of web interfaces and explore use cases for combined visualization of software cities and HTML structure.

Abstract: Software visualization, which uses data from dynamic program analysis, can
help to explore and understand the behavior of software systems. It is common
that large software systems offer a web interface for user interaction.
Usually, available web interfaces are not regarded in software visualization
tools. This paper introduces additions to the web-based live tracing software
visualization tool ExplorViz: We add an embedded web view for instrumented
applications in the 3D visualization to ease interaction with the given
applications and enable the exploration of the thereby displayed HTML content.
Namely, the Document Object Model (DOM) is visualized via a three-dimensional
representation of the HTML structure in same-origin contexts.
  Our visualization approach is evaluated in a preliminary user study. The
study results give insights into the potential use cases, benefits, and
shortcomings of our implemented approach. Based on our study results, we
propose directions for further research to support the visual exploration of
web interfaces and explore use cases for the combined visualization of software
cities and HTML structure.
  Video URL: https://youtu.be/wBWKlbvzOOE

</details>


### [4] [VibeCodeHPC: An Agent-Based Iterative Prompting Auto-Tuner for HPC Code Generation Using LLMs](https://arxiv.org/abs/2510.00031)
*Shun-ichiro Hayashi,Koki Morita,Daichi Mukunoki,Tetsuya Hoshino,Takahiro Katagiri*

Main category: cs.SE

TL;DR: VibeCodeHPC is an automatic tuning system for HPC programs using multi-agent LLMs with role allocation and iterative prompt refinement.


<details>
  <summary>Details</summary>
Motivation: To improve HPC program optimization through effective multi-agent collaboration and automated code generation.

Method: Uses four agent roles (Project Manager, System Engineer, Programmer, Continuous Delivery) with dynamic deployment and activity monitoring for iterative prompt refinement.

Result: Achieved higher-quality code generation per unit time compared to solo-agent, with better identification of requirement violations in GPU code conversion case study.

Conclusion: Multi-agent LLM configuration with dynamic deployment and monitoring enables more effective HPC program optimization than single-agent approaches.

Abstract: We propose VibeCodeHPC, an automatic tuning system for HPC programs based on
multi-agent LLMs for code generation. VibeCodeHPC tunes programs through
multi-agent role allocation and iterative prompt refinement. We describe the
system configuration with four roles: Project Manager (PM), System Engineer
(SE), Programmer (PG), and Continuous Delivery (CD). We introduce dynamic agent
deployment and activity monitoring functions to facilitate effective
multi-agent collaboration. In our case study, we convert and optimize CPU-based
matrix-matrix multiplication code written in C to GPU code using CUDA. The
multi-agent configuration of VibeCodeHPC achieved higher-quality code
generation per unit time compared to a solo-agent configuration. Additionally,
the dynamic agent deployment and activity monitoring capabilities facilitated
more effective identification of requirement violations and other issues.

</details>


### [5] [A Scalable Framework for Safety Assurance of Self-Driving Vehicles based on Assurance 2.0](https://arxiv.org/abs/2510.00092)
*Shufeng Chen,Mariat James Elizebeth,Robab Aghazadeh Chakherlou,Xingyu Zhao,Eric Barbier,Siddartha Khastgir,Paul Jennings*

Main category: cs.SE

TL;DR: Assurance 2.0 framework with decomposition strategies for safety arguments in AI-based self-driving vehicles, using 5M1E model for comprehensive coverage.


<details>
  <summary>Details</summary>
Motivation: Address limitations in confidence measurement, residual doubt management, and practical handling of defeaters in complex autonomous systems.

Method: Three-tiered decomposition strategy: SDV development phases (RE, VnV, PD), Product Development Lifecycle, and adapted 5M1E model (Man, Machine, Method, Material, Measurement, Environment).

Result: Framework enables fine-grained traceability of safety claims, evidence, and potential defeaters through structured decomposition.

Conclusion: The decomposition framework provides comprehensive coverage and supports rigorous assurance for complex autonomous systems like self-driving vehicles.

Abstract: Assurance 2.0 is a modern framework developed to address the assurance
challenges of increasingly complex, adaptive, and autonomous systems. Building
on the traditional Claims-Argument-Evidence (CAE) model, it introduces reusable
assurance theories and explicit counterarguments (defeaters) to enhance rigor,
transparency, and adaptability. It supports continuous, incremental assurance,
enabling innovation without compromising safety. However, limitations persist
in confidence measurement, residual doubt management, automation support, and
the practical handling of defeaters and confirmation bias. This paper presents
\textcolor{black}{a set of decomposition frameworks to identify a complete set
of safety arguments and measure their corresponding evidence.} Grounded in the
Assurance 2.0 paradigm, the framework is instantiated through a structured
template and employs a three-tiered decomposition strategy. \textcolor{black}{A
case study regarding the application of the decomposition framework in the
end-to-end (E2E) AI-based Self-Driving Vehicle (SDV) development is also
presented in this paper.} At the top level, the SDV development is divided into
three critical phases: Requirements Engineering (RE), Verification and
Validation (VnV), and Post-Deployment (PD). Each phase is further decomposed
according to its Product Development Lifecycle (PDLC). To ensure comprehensive
coverage, each PDLC is analyzed using an adapted 5M1E model (Man, Machine,
Method, Material, Measurement, and Environment). Originally developed for
manufacturing quality control, the 5M1E model is reinterpreted and contextually
mapped to the assurance domain. This enables a multi-dimensional decomposition
that supports fine-grained traceability of safety claims, evidence, and
potential defeaters.

</details>


### [6] [Container Orchestration Patterns for Optimizing Resource Use](https://arxiv.org/abs/2510.00197)
*Diogo Maia,Filipe Correia,Andr√© Restivo,Paulo Queiroz*

Main category: cs.SE

TL;DR: The paper identifies three key orchestration resource optimization patterns for service-based architectures: Preemptive Scheduling, Service Balancing, and Garbage Collection to address challenges in service orchestration.


<details>
  <summary>Details</summary>
Motivation: Service orchestration remains challenging for newcomers due to lack of clarity and standardization in existing resources, limiting adoption of best practices in the software industry.

Method: Analyzed existing literature and tools to identify common orchestration practices and defined three optimization patterns based on findings.

Result: Defined three key patterns: Preemptive Scheduling (priority-based resource allocation), Service Balancing (node restructuring for better resource usage), and Garbage Collection (cleanup mechanisms for resource optimization).

Conclusion: These patterns serve as foundational elements for improving orchestration practices and fostering broader adoption in service-based architectures.

Abstract: Service-based architectures provide substantial benefits, yet service
orchestration remains a challenge, particularly for newcomers. While various
resources on orchestration techniques exist, they often lack clarity and
standardization, making best practices difficult to implement and limiting
their adoption within the software industry.
  To address this gap, we analyzed existing literature and tools to identify
common orchestration practices. Based on our findings, we define three key
orchestration resource optimization patterns: {\sc Preemptive Scheduling}, {\sc
Service Balancing}, and {\sc Garbage Collection}. {\sc Preemptive Scheduling}
allows the allocation of sufficient resources for services of higher priority
in stressful situations, while {\sc Service Balancing} enables a restructuring
of the nodes to allow better resource usage. To end, {\sc Garbage Collection}
creates cleanup mechanisms to better understand the system's resource usage and
optimize it. These patterns serve as foundational elements for improving
orchestration practices and fostering broader adoption in service-based
architectures.

</details>


### [7] [Which Programming Language and Model Work Best With LLM-as-a-Judge For Code Retrieval?](https://arxiv.org/abs/2510.00324)
*Lucas Roberts,Denisa Roberts*

Main category: cs.SE

TL;DR: This paper studies using LLMs for code search and annotation, comparing retrieval methods and programming languages to improve human-AI alignment in relevance judgments.


<details>
  <summary>Details</summary>
Motivation: Code search lags behind text search due to high annotation costs requiring programming expertise. The research aims to leverage LLMs to overcome this limitation and improve code retrieval.

Method: Compared sparse vs. semantic retrieval representations across multiple programming languages (C, Java, Javascript, Go, Python) using LLMs for code annotation and evaluation. Used transpilers to create scalable benchmarks and compared human-AI relevance agreement.

Result: Found that retriever choice and programming language exhibit affinities that improve human-AI alignment. Different representations perform variably across languages. Human-AI agreement rates matched worst-case human-human agreement.

Conclusion: LLMs can effectively retrieve and annotate code, with significant performance implications based on retriever and language selection. Transpilers enable scalable benchmark creation across programming languages.

Abstract: Code search is an important information retrieval application. Benefits of
better code search include faster new developer on-boarding, reduced software
maintenance, and ease of understanding for large repositories. Despite
improvements in search algorithms and search benchmarks, the domain of code
search has lagged behind. One reason is the high cost of human annotation for
code queries and answers. While humans may annotate search results in general
text QA systems, code annotations require specialized knowledge of a
programming language (PL), as well as domain specific software engineering
knowledge. In this work we study the use of Large Language Models (LLMs) to
retrieve code at the level of functions and to generate annotations for code
search results. We compare the impact of the retriever representation (sparse
vs. semantic), programming language, and LLM by comparing human annotations
across several popular languages (C, Java, Javascript, Go, and Python). We
focus on repositories that implement common data structures likely to be
implemented in any PLs. For the same human annotations, we compare several
LLM-as-a-Judge models to evaluate programming language and other affinities
between LLMs. We find that the chosen retriever and PL exhibit affinities that
can be leveraged to improve alignment of human and AI relevance determinations,
with significant performance implications. We also find differences in
representation (sparse vs. semantic) across PLs that impact alignment of human
and AI relevance determinations. We propose using transpilers to bootstrap
scalable code search benchmark datasets in other PLs and in a case study
demonstrate that human-AI relevance agreement rates largely match the (worst
case) human-human agreement under study. The application code used in this work
is available at \href{https://github.com/rlucas7/code-searcher/}{this github
repo}.

</details>


### [8] [Vibe Coding in Practice: Motivations, Challenges, and a Future Outlook -- a Grey Literature Review](https://arxiv.org/abs/2510.00328)
*Ahmed Fawzy,Amjed Tahir,Kelly Blincoe*

Main category: cs.SE

TL;DR: Vibe coding enables rapid AI-assisted development but creates a speed-quality trade-off where users skip testing and produce vulnerable code they can't debug.


<details>
  <summary>Details</summary>
Motivation: To systematically investigate why users engage in vibe coding, their experiences, and how they approach quality assurance with AI-generated code.

Method: Conducted a systematic grey literature review of 101 practitioner sources, extracting 518 firsthand behavioral accounts about vibe coding practices.

Result: Revealed a speed-quality trade-off paradox: users experience rapid success but perceive code as flawed, often skipping testing and delegating QA back to AI tools.

Conclusion: Vibe coding lowers barriers and accelerates prototyping but creates vulnerable developers who can't debug their own code, requiring responsible use guidance to prevent QA crisis.

Abstract: AI code generation tools are transforming software development, especially
for novice and non-software developers, by enabling them to write code and
build applications faster and with little to no human intervention. Vibe coding
is the practice where users rely on AI code generation tools through intuition
and trial-and-error without necessarily understanding the underlying code.
Despite widespread adoption, no research has systematically investigated why
users engage in vibe coding, what they experience while doing so, and how they
approach quality assurance (QA) and perceive the quality of the AI-generated
code. To this end, we conduct a systematic grey literature review of 101
practitioner sources, extracting 518 firsthand behavioral accounts about vibe
coding practices, challenges, and limitations. Our analysis reveals a
speed-quality trade-off paradox, where vibe coders are motivated by speed and
accessibility, often experiencing rapid ``instant success and flow'', yet most
perceive the resulting code as fast but flawed. QA practices are frequently
overlooked, with many skipping testing, relying on the models' or tools'
outputs without modification, or delegating checks back to the AI code
generation tools. This creates a new class of vulnerable software developers,
particularly those who build a product but are unable to debug it when issues
arise. We argue that vibe coding lowers barriers and accelerates prototyping,
but at the cost of reliability and maintainability. These insights carry
implications for tool designers and software development teams. Understanding
how vibe coding is practiced today is crucial for guiding its responsible use
and preventing a broader QA crisis in AI-assisted development.

</details>


### [9] [Beyond Pass/Fail: The Story of Learning-Based Testing](https://arxiv.org/abs/2510.00450)
*Sheikh Md. Mushfiqur Rahman,Nasir Eisty*

Main category: cs.SE

TL;DR: Learning-Based Testing (LBT) combines learning and testing to achieve comprehensive behavioral adequacy, using active learning to infer system models with minimal initial test cases.


<details>
  <summary>Details</summary>
Motivation: To provide a systematic review of LBT implementations across different program types and evaluate current research status, highlighting LBT's potential for commercial software testing.

Method: Conducted a systematic literature review of various LBT implementations, exploring theoretical frameworks, existing tools, libraries, and industrial case studies.

Result: LBT has solid theoretical foundations demonstrating efficacy in testing both procedural and reactive programs, with successful industrial applications showing its potential in commercial settings.

Conclusion: LBT is a promising software testing technique with significant potential that benefits both practitioners and researchers, though it remains in early stages of development.

Abstract: Learning-Based Testing (LBT) merges learning and testing processes to achieve
both testing and behavioral adequacy. LBT utilizes active learning to infer the
model of the System Under Test (SUT), enabling scalability for large and
complex programs by requiring only a minimal set of initial test cases. The
core principle of LBT is that the SUT's behavior can be thoroughly inferred by
progressively generating test cases and subjecting the SUT to testing, thereby
ensuring comprehensive testing. Despite being in its early stages, LBT has a
solid foundation of theoretical research demonstrating its efficacy in testing
both procedural and reactive programs. This paper provides a systematic
literature review of various LBT implementations across different program types
and evaluates the current state of research in this field. We explore diverse
theoretical frameworks, existing tools, and libraries within the LBT domain to
illustrate the concept's evolution and current research status. Additionally,
we examine case studies involving the application of LBT tools in industrial
settings, highlighting their potential and effectiveness in commercial software
testing. This systematic literature review aims to offer researchers a
comprehensive perspective on the inception and development of LBT, presenting
it as a promising technique in software testing. By unveiling LBT's
underutilized potential, this paper seeks to significantly benefit the
practitioners and research community.

</details>


### [10] [Analyzing Latent Concepts in Code Language Models](https://arxiv.org/abs/2510.00476)
*Arushi Sharma,Vedant Pungliya,Christopher J. Quinn,Ali Jannesari*

Main category: cs.SE

TL;DR: Code Concept Analysis (CoCoA) is a global interpretability framework that clusters token embeddings into human-interpretable concepts for code language models, improving explainability and robustness.


<details>
  <summary>Details</summary>
Motivation: Interpreting internal behavior of code language models is challenging but critical for trust, transparency, and semantic robustness in applications.

Method: Proposes CoCoA framework that clusters contextualized token embeddings into concept groups using hybrid annotation combining static analysis tools and LLMs for scalable labeling across abstraction levels.

Result: CoCoA discovers stable concepts under semantic perturbations (CSI = 0.288), evolves predictably with fine-tuning, and concept-augmented explanations improve human-centric explainability by 37 percentage points compared to token-level attributions.

Conclusion: CoCoA effectively uncovers interpretable latent structures in code models, enabling better understanding of model behavior and improving explanation quality for human users.

Abstract: Interpreting the internal behavior of large language models trained on code
remains a critical challenge, particularly for applications demanding trust,
transparency, and semantic robustness. We propose Code Concept Analysis
(CoCoA): a global post-hoc interpretability framework that uncovers emergent
lexical, syntactic, and semantic structures in a code language model's
representation space by clustering contextualized token embeddings into
human-interpretable concept groups. We propose a hybrid annotation pipeline
that combines static analysis tool-based syntactic alignment with
prompt-engineered large language models (LLMs), enabling scalable labeling of
latent concepts across abstraction levels. We analyse the distribution of
concepts across layers and across three finetuning tasks. Emergent concept
clusters can help identify unexpected latent interactions and be used to
identify trends and biases within the model's learned representations. We
further integrate LCA with local attribution methods to produce
concept-grounded explanations, improving the coherence and interpretability of
token-level saliency. Empirical evaluations across multiple models and tasks
show that LCA discovers concepts that remain stable under semantic-preserving
perturbations (average Cluster Sensitivity Index, CSI = 0.288) and evolve
predictably with fine-tuning. In a user study, concept-augmented explanations
disambiguate token roles. In a user study on the programming-language
classification task, concept-augmented explanations disambiguated token roles
and improved human-centric explainability by 37 percentage points compared with
token-level attributions using Integrated Gradients.

</details>


### [11] [CodeChemist: Functional Knowledge Transfer for Low-Resource Code Generation via Test-Time Scaling](https://arxiv.org/abs/2510.00501)
*Kaixin Wang,Tianlin Li,Xiaoyu Zhang,Aishan Liu,Xianglong Liu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou,and Bin Shi*

Main category: cs.SE

TL;DR: CodeChemist is a test-time scaling framework that transfers functional knowledge from high-resource to low-resource programming languages using generated test cases and multi-temperature hedged sampling, improving code generation performance without retraining.


<details>
  <summary>Details</summary>
Motivation: CodeLLMs perform inconsistently across programming languages, with low-resource PLs suffering most due to limited training data, creating a need for efficient knowledge transfer methods.

Method: Generates and executes code in high-resource PLs to create test cases, then uses multi-temperature hedged sampling to generate code in low-resource PLs and selects the best one based on test case pass rates.

Result: Outperforms existing test-time scaling approaches and boosts code generation performance for low-resource PLs without requiring model retraining.

Conclusion: CodeChemist provides an effective framework for functional knowledge transfer between programming languages, addressing the performance gap between high-resource and low-resource PLs in code generation tasks.

Abstract: Code Large Language Models (CodeLLMs) are increasingly used in code
generation tasks across a wide range of applications. However, their
performance is often inconsistent across different programming languages (PLs),
with low-resource PLs suffering the most due to limited training data. In this
paper, we present CodeChemist, a novel and efficient framework for test-time
scaling that enables functional knowledge transfer from high-resource to
low-resource PLs using generated test cases. CodeChemist first generates and
executes code in high-resource PLs to create test cases that encapsulate
functional knowledge. It then uses multi-temperature hedged sampling to
generate code snippets in the low-resource PL and selects the best one based on
the pass rate of the test cases. Our extensive experiments show that
CodeChemist outperforms existing test-time scaling approaches, boosting the
performance of code generation for low-resource PLs without requiring any model
retraining.

</details>


### [12] [Architectural Transformations and Emerging Verification Demands in AI-Enabled Cyber-Physical Systems](https://arxiv.org/abs/2510.00519)
*Hadiza Umar Yusuf,Khouloud Gaaloul*

Main category: cs.SE

TL;DR: This paper investigates architectural differences between AI-driven and traditional control models in Cyber-Physical Systems (CPS), focusing on their implications for system verification.


<details>
  <summary>Details</summary>
Motivation: AI integration in CPS enhances adaptability but introduces complexity that affects control optimization and reliability. There's a gap in understanding how this shift impacts CPS architecture, operational complexity, and verification practices.

Method: The study investigates architectural distinctions between AI-driven and traditional control models designed in Simulink.

Result: The research addresses the gap in understanding how AI integration affects CPS architecture and verification practices.

Conclusion: The paper provides insights into the architectural differences between AI-driven and traditional CPS control models and their verification implications.

Abstract: In the world of Cyber-Physical Systems (CPS), a captivating real-time fusion
occurs where digital technology meets the physical world. This synergy has been
significantly transformed by the integration of artificial intelligence (AI), a
move that dramatically enhances system adaptability and introduces a layer of
complexity that impacts CPS control optimization and reliability. Despite
advancements in AI integration, a significant gap remains in understanding how
this shift affects CPS architecture, operational complexity, and verification
practices. The extended abstract addresses this gap by investigating
architectural distinctions between AI-driven and traditional control models
designed in Simulink and their respective implications for system verification.

</details>


### [13] [LSPFuzz: Hunting Bugs in Language Servers](https://arxiv.org/abs/2510.00532)
*Hengcheng Zhu,Songqiang Chen,Valerio Terragni,Lili Wei,Jiarong Wu,Yepang Liu,Shing-Chi Cheung*

Main category: cs.SE

TL;DR: LSPFuzz is a grey-box hybrid fuzzer designed specifically for testing Language Server Protocol (LSP) servers, addressing the gap in LSP server reliability testing.


<details>
  <summary>Details</summary>
Motivation: LSP servers are widely used but lack dedicated testing techniques, and their crashes or vulnerabilities can significantly impact developer productivity and security.

Method: Two-stage mutation pipeline: syntax-aware mutations to source code followed by context-aware dispatching of editor operations, using grey-box hybrid fuzzing approach.

Result: LSPFuzz outperformed baseline fuzzers and discovered 51 bugs in real-world LSP servers, with 42 confirmed, 26 fixed, and 2 assigned CVE numbers.

Conclusion: LSPFuzz advances LSP server quality assurance by providing an effective testing tool and foundational insights for future research in this domain.

Abstract: The Language Server Protocol (LSP) has revolutionized the integration of code
intelligence in modern software development. There are approximately 300 LSP
server implementations for various languages and 50 editors offering LSP
integration. However, the reliability of LSP servers is a growing concern, as
crashes can disable all code intelligence features and significantly impact
productivity, while vulnerabilities can put developers at risk even when
editing untrusted source code. Despite the widespread adoption of LSP, no
existing techniques specifically target LSP server testing. To bridge this gap,
we present LSPFuzz, a grey-box hybrid fuzzer for systematic LSP server testing.
Our key insight is that effective LSP server testing requires holistic mutation
of source code and editor operations, as bugs often manifest from their
combinations. To satisfy the sophisticated constraints of LSP and effectively
explore the input space, we employ a two-stage mutation pipeline: syntax-aware
mutations to source code, followed by context-aware dispatching of editor
operations. We evaluated LSPFuzz on four widely used LSP servers. LSPFuzz
demonstrated superior performance compared to baseline fuzzers, and uncovered
previously unknown bugs in real-world LSP servers. Of the 51 bugs we reported,
42 have been confirmed, 26 have been fixed by developers, and two have been
assigned CVE numbers. Our work advances the quality assurance of LSP servers,
providing both a practical tool and foundational insights for future research
in this domain.

</details>


### [14] [AI-Driven Self-Evolving Software: A Promising Path Toward Software Automation](https://arxiv.org/abs/2510.00591)
*Liyi Cai,Yijie Ren,Yitong Zhang,Jia Li*

Main category: cs.SE

TL;DR: AI-Driven Self-Evolving Software enables continuous software evolution through direct user interaction, moving beyond AI assistance to become a core component that autonomously interprets requirements, generates code, and integrates new functionalities.


<details>
  <summary>Details</summary>
Motivation: Current AI in software development primarily serves as assistants to humans, requiring explicit human intervention. The goal is to move AI beyond assistance to become a core component enabling genuine software automation without human dependency.

Method: A lightweight prototype built on multi-agent architecture that autonomously interprets user requirements, generates and validates code, and integrates new functionalities through direct interaction with users.

Result: Case studies across multiple representative scenarios show the prototype can reliably construct and reuse functionality, providing evidence that such systems can scale to more sophisticated applications.

Conclusion: AI-Driven Self-Evolving Software demonstrates feasibility of continuous software evolution through user interaction, paving the way toward truly automated software development where AI becomes a core component rather than just an assistant.

Abstract: Software automation has long been a central goal of software engineering,
striving for software development that proceeds without human intervention.
Recent efforts have leveraged Artificial Intelligence (AI) to advance software
automation with notable progress. However, current AI functions primarily as
assistants to human developers, leaving software development still dependent on
explicit human intervention. This raises a fundamental question: Can AI move
beyond its role as an assistant to become a core component of software, thereby
enabling genuine software automation? To investigate this vision, we introduce
AI-Driven Self-Evolving Software, a new form of software that evolves
continuously through direct interaction with users. We demonstrate the
feasibility of this idea with a lightweight prototype built on a multi-agent
architecture that autonomously interprets user requirements, generates and
validates code, and integrates new functionalities. Case studies across
multiple representative scenarios show that the prototype can reliably
construct and reuse functionality, providing early evidence that such software
systems can scale to more sophisticated applications and pave the way toward
truly automated software development. We make code and cases in this work
publicly available at https://anonymous.4open.science/r/live-software.

</details>


### [15] [PyTrim: A Practical Tool for Reducing Python Dependency Bloat](https://arxiv.org/abs/2510.00674)
*Konstantinos Karakatsanis,Georgios Alexopoulos,Ioannis Karyotakis,Foivos Timotheos Proestakis,Evangelos Talos,Panos Louridas,Dimitris Mitropoulos*

Main category: cs.SE

TL;DR: PYTRIM is an automated system that removes unused dependencies in Python projects across source code and configuration files, achieving 98.3% accuracy in replicating human-made changes and successfully trimming dependencies in 39 open-source packages.


<details>
  <summary>Details</summary>
Motivation: Dependency bloat in Python projects increases maintenance costs and security risks, and while detection tools exist, removing these dependencies requires manual effort and expertise.

Method: PYTRIM is an end-to-end system that eliminates unused imports and package declarations across Python source files and configuration files. It has a modular design that works with any detection tool and includes a novel dynamic analysis component to improve dependency detection recall.

Result: Evaluation on 37 merged pull requests showed 98.3% accuracy in replicating human-made changes. Applied to 971 open-source packages, PYTRIM identified and trimmed bloated dependencies in 39 packages, with 6 pull requests already accepted and merged.

Conclusion: PYTRIM effectively automates the removal of unused dependencies in Python projects, demonstrating high accuracy and practical impact on real-world open-source packages.

Abstract: Dependency bloat is a persistent challenge in Python projects, which
increases maintenance costs and security risks. While numerous tools exist for
detecting unused dependencies in Python, removing these dependencies across the
source code and configuration files of a project requires manual effort and
expertise.
  To tackle this challenge we introduce PYTRIM, an end-to-end system to
automate this process. PYTRIM eliminates unused imports and package
declarations across a variety of file types, including Python source and
configuration files such as requirements.txt and setup.py. PYTRIM's modular
design makes it agnostic to the source of dependency bloat information,
enabling integration with any detection tool. Beyond its contribution when it
comes to automation, PYTRIM also incorporates a novel dynamic analysis
component that improves dependency detection recall.
  Our evaluation of PYTRIM's end-to-end effectiveness on a ground-truth dataset
of 37 merged pull requests from prior work, shows that PYTRIM achieves 98.3%
accuracy in replicating human-made changes. To show its practical impact, we
run PYTRIM on 971 open-source packages, identifying and trimming bloated
dependencies in 39 of them. For each case, we submit a corresponding pull
request, 6 of which have already been accepted and merged. PYTRIM is available
as an open-source project, encouraging community contributions and further
development.
  Video demonstration: https://youtu.be/LqTEdOUbJRI
  Code repository: https://github.com/TrimTeam/PyTrim

</details>


### [16] [TShape: Rescuing Machine Learning Models from Complex Shapelet Anomalies](https://arxiv.org/abs/2510.00680)
*Hang Cui,Jingjing Li,Haotian Si,Quan Zhou,Changhua Pei,Gaogang Xie,Dan Pei*

Main category: cs.SE

TL;DR: TShape is a novel framework for time series anomaly detection that uses patch-wise dual attention with multi-scale convolution to detect complex shapelet anomalies, achieving 10% F1 score improvement over state-of-the-art methods.


<details>
  <summary>Details</summary>
Motivation: Existing TSAD methods struggle to detect shapelet anomalies - complex shape deviations that are obvious to humans but challenging for ML algorithms, particularly in dynamic industrial environments.

Method: TShape introduces a patch-wise dual attention mechanism with multi-scale convolution to model sub-sequence variations by balancing local shape features with global contextual dependencies.

Result: Extensive evaluation on five benchmarks shows TShape outperforms state-of-the-art models with average 10% F1 score improvement in anomaly detection.

Conclusion: Ablation studies and attention visualizations confirm the robustness and adaptability of TShape for detecting complex shapelet shapes in time series data.

Abstract: Time series anomaly detection (TSAD) is critical for maintaining the
reliability of modern IT infrastructures, where complex anomalies frequently
arise in highly dynamic environments. In this paper, we present TShape, a novel
framework designed to address the challenges in industrial time series anomaly
detection. Existing methods often struggle to detect shapelet anomalies that
manifest as complex shape deviations, which appear obvious to human experts but
prove challenging for machine learning algorithms. TShape introduces a
patch-wise dual attention mechanism with multi-scale convolution to model
intricate sub-sequence variations by balancing local, fine-grained shape
features with global contextual dependencies. Our extensive evaluation on five
diverse benchmarks demonstrates that TShape outperforms existing
state-of-the-art models, achieving an average 10\% F1 score improvement in
anomaly detection. Additionally, ablation studies and attention visualizations
confirm the essential contributions of each component, highlighting the
robustness and adaptability of TShape to complex shapelet shapes in time series
data.

</details>


### [17] [Maven-Lockfile: High Integrity Rebuild of Past Java Releases](https://arxiv.org/abs/2510.00730)
*Larissa Schmid,Elias Lundell,Yogya Gamage,Benoit Baudry,Martin Monperrus*

Main category: cs.SE

TL;DR: Maven-Lockfile provides lockfile generation and update capabilities for Maven projects, enabling reproducible builds and dependency integrity verification in the Java ecosystem.


<details>
  <summary>Details</summary>
Motivation: Maven lacks native lockfile support, which complicates reproducible and secure builds in Java projects that depend on many third-party libraries.

Method: The tool generates and updates lockfiles that capture all direct and transitive dependencies with their checksums, supporting rebuilding projects from past versions.

Result: Evaluation shows Maven-Lockfile can reproduce builds from historical commits and detect tampered artifacts with minimal configuration.

Conclusion: Maven-Lockfile equips Java projects with modern build integrity and reproducibility, fostering future research on software supply chain security in Java.

Abstract: Modern software projects depend on many third-party libraries, complicating
reproducible and secure builds. Several package managers address this with the
generation of a lockfile that freezes dependency versions and can be used to
verify the integrity of dependencies. Yet, Maven, one of the most important
package managers in the Java ecosystem, lacks native support for a lockfile. We
present Maven-Lockfile to generate and update lockfiles, with support for
rebuilding projects from past versions. Our lockfiles capture all direct and
transitive dependencies with their checksums, enabling high integrity builds.
Our evaluation shows that Maven-Lockfile can reproduce builds from historical
commits and is able to detect tampered artifacts. With minimal configuration,
Maven-Lockfile equips Java projects with modern build integrity and build
reproducibility, and fosters future research on software supply chain security
in Java.

</details>


### [18] [AI Where It Matters: Where, Why, and How Developers Want AI Support in Daily Work](https://arxiv.org/abs/2510.00762)
*Rudrajit Choudhuri,Carmen Badea,Christian Bird,Jenna Butler,Rob DeLine,Brian Houck*

Main category: cs.SE

TL;DR: A large-scale study of 860 developers reveals task-specific patterns in AI adoption: strong use in coding/testing, high demand for reducing documentation/operations toil, and clear limits for mentoring work. Responsible AI priorities vary by context.


<details>
  <summary>Details</summary>
Motivation: To provide empirical guidance on where developers most need AI support and how to design it responsibly, addressing the gap in understanding AI adoption patterns in software work.

Method: Large-scale mixed-methods study of 860 developers using cognitive appraisal theory to examine where, why, and how developers seek or limit AI help across different tasks.

Result: Task evaluations predict AI adoption patterns: strong current use in core work (coding/testing), high demand for reducing toil (documentation/operations), and clear limits for identity/relationship work (mentoring). Responsible AI priorities vary by task context.

Conclusion: The study provides concrete, contextual guidance for delivering AI support where it matters most to developers, with varying responsible AI priorities depending on whether tasks are systems-facing or human-facing.

Abstract: Generative AI is reshaping software work, yet we lack clear guidance on where
developers most need and want support, and how to design it responsibly. We
report a large-scale, mixed-methods study of N=860 developers that examines
where, why, and how they seek or limit AI help, providing the first task-aware,
empirically validated mapping from developers' perceptions of their tasks to AI
adoption patterns and responsible AI priorities. Using cognitive appraisal
theory, we show that task evaluations predict openness to and use of AI,
revealing distinct patterns: strong current use and a desire for improvement in
core work (e.g., coding, testing); high demand to reduce toil (e.g.,
documentation, operations); and clear limits for identity- and
relationship-centric work (e.g., mentoring). Priorities for responsible AI
support vary by context: reliability and security for systems-facing tasks;
transparency, alignment, and steerability to maintain control; and fairness and
inclusiveness for human-facing work. Our results offer concrete, contextual
guidance for delivering AI where it matters to developers and their work.

</details>


### [19] [Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning](https://arxiv.org/abs/2510.00881)
*Patrizio Migliarini,Mashal Afzal Memon,Marco Autili,Paola Inverardi*

Main category: cs.SE

TL;DR: LLMs show promising ethical reasoning capabilities with 73.3% theory consistency and 86.7% moral acceptability agreement in zero-shot testing across 30 real-world ethical scenarios.


<details>
  <summary>Details</summary>
Motivation: To assess whether LLMs can serve as reliable ethical inference engines in software engineering tools, particularly for judgment under uncertainty and ethically significant contexts.

Method: Fully automated framework testing 16 LLMs in zero-shot setting using 30 real-world ethically charged scenarios, comparing responses against expert ethicists using inter-model agreement metrics.

Result: LLMs achieved 73.3% Theory Consistency Rate and 86.7% Binary Agreement Rate on moral acceptability, with interpretable divergences mainly in ethically ambiguous cases.

Conclusion: LLMs demonstrate sufficient interpretive stability and theory-consistent reasoning to potentially serve as ethical inference engines in SE pipelines, enabling scalable and auditable ethical reasoning integration.

Abstract: Large Language Models (LLMs) are increasingly integrated into software
engineering (SE) tools for tasks that extend beyond code synthesis, including
judgment under uncertainty and reasoning in ethically significant contexts. We
present a fully automated framework for assessing ethical reasoning
capabilities across 16 LLMs in a zero-shot setting, using 30 real-world
ethically charged scenarios. Each model is prompted to identify the most
applicable ethical theory to an action, assess its moral acceptability, and
explain the reasoning behind their choice. Responses are compared against
expert ethicists' choices using inter-model agreement metrics. Our results show
that LLMs achieve an average Theory Consistency Rate (TCR) of 73.3% and Binary
Agreement Rate (BAR) on moral acceptability of 86.7%, with interpretable
divergences concentrated in ethically ambiguous cases. A qualitative analysis
of free-text explanations reveals strong conceptual convergence across models
despite surface-level lexical diversity. These findings support the potential
viability of LLMs as ethical inference engines within SE pipelines, enabling
scalable, auditable, and adaptive integration of user-aligned ethical
reasoning. Our focus is the Ethical Interpreter component of a broader
profiling pipeline: we evaluate whether current LLMs exhibit sufficient
interpretive stability and theory-consistent reasoning to support automated
profiling.

</details>


### [20] [On Effective Semantic Translation for Code: A Study Based on Pseudocode](https://arxiv.org/abs/2510.00920)
*Songqiang Chen,Congying Xu,Jingyi Chen,Jialun Cao,Jiarong Wu,Shing-Chi Cheung*

Main category: cs.SE

TL;DR: Pseudocode-based code translation improves LLM performance by first converting code to pseudocode then to target language, complementing direct translation especially for flexible-to-rigid language pairs and low-resource scenarios.


<details>
  <summary>Details</summary>
Motivation: Direct code-to-code translation struggles with accuracy, so researchers explore pseudocode-based approach inspired by human semantic translation to improve LLM performance in code translation.

Method: Empirical study comparing direct and pseudocode-based translation approaches on 9,690 tasks across 6 programming languages using 5 popular LLMs.

Result: Pseudocode-based translation effectively complements direct translation, particularly for flexible-to-rigid PL conversions and low-resource Rust scenarios, showing advantages in handling complex programs and reducing implementation distractions.

Conclusion: Combining both approaches leverages their complementary strengths, though pseudocode limitations include incorrect, incomplete, or ambiguous pseudocode generation.

Abstract: Large language models (LLMs) show great potential in code translation.
However, accurate translation remains challenging when using the commonly
adopted direct code-to-code translation approach, which converts a program into
the target programming language (PL) in a single step. Inspired by the success
of incorporating intermediate steps to guide LLMs in resolving challenging
tasks, we explore pseudocode-based code translation, which emulates the human
semantic translation by first interpreting the program's intent and logic into
pseudocode and then implementing it in the target PL. We find that
pseudocode-based translation helps translate programs that direct translation
struggles to handle. Nonetheless, the effectiveness, advantages, and
limitations of this approach remain underexplored. To bridge this gap, we
present an empirical study on pseudocode-based code translation, aiming to
investigate its effectiveness in enhancing the direct translation approach,
illuminate its effective usage, and identify limitations hindering its
potential benefits. By comparing direct and pseudocode-based translation
approaches on 9,690 translation tasks across six PLs with five popular LLMs, we
demonstrate that pseudocode-based translation can effectively complement direct
translation, particularly when translating from flexible to rigid PLs or
dealing with low-resource Rust. Based on these findings, we suggest adopting
strategies that combine the complementary strengths of both approaches to
enhance code translation accuracy. We also reveal the advantages of
pseudocode-based translation in disentangling translations of complicated
programs and mitigating distractions from detailed implementations in original
programs, as well as its limitations due to incorrect, incomplete, or ambiguous
pseudocode.

</details>


### [21] [ChatGPT in Introductory Programming: Counterbalanced Evaluation of Code Quality, Conceptual Learning, and Student Perceptions](https://arxiv.org/abs/2510.00946)
*Shiza Andleeb,Brandon Kantorski,Jeffrey C. Carver*

Main category: cs.SE

TL;DR: ChatGPT improves code quality and efficiency for novice programmers but has mixed effects on conceptual understanding, requiring structured integration to support learning.


<details>
  <summary>Details</summary>
Motivation: To investigate how ChatGPT access affects code quality, conceptual understanding, task completion times, and student perceptions in introductory programming courses.

Method: Counterbalanced quasi-experimental study where students alternated between ChatGPT and non-ChatGPT conditions across two programming assignments in C (functions and structures), using multidimensional rubrics, conceptual post-surveys, and task completion time measurements.

Result: Students with ChatGPT access produced significantly higher code quality scores and completed tasks faster, but conceptual understanding gains were mixed (lower for functions, higher for structures). Students reported positive experiences for debugging but concerns about accuracy and long-term skill development.

Conclusion: ChatGPT enhances code quality and efficiency but doesn't uniformly improve conceptual understanding; structured integration and complementary instructional strategies are needed to foster independent problem-solving skills.

Abstract: Background: Large language models (LLMs) such as ChatGPT are increasingly
used in introductory programming courses to provide real-time code generation,
debugging, and explanations. While these tools can boost productivity and code
quality, concerns remain about over-reliance and potential impacts on
conceptual learning. Objective: To investigate how ChatGPT access affects code
quality, conceptual understanding, task completion times, and student
perceptions in a CS1 course. Methods: We conducted a counterbalanced,
quasi-experimental study in which students alternated between ChatGPT and
non-ChatGPT conditions across two programming assignments in C (functions and
structures). We evaluated their code submissions using multidimensional
rubrics, conceptual post-surveys, and task completion time. Results: Students
who had access to ChatGPT produced significantly higher rubric scores for code
quality and completed tasks in less time compared to those without access.
However, gains in conceptual understanding were mixed, lower for the functions
topic but higher for the structures topic. Students reported positive
experiences with ChatGPT, citing its value for debugging and practice, while
expressing concerns about accuracy and long-term skill development.
Conclusions: ChatGPT can enhance code quality and efficiency for novice
programmers, but may not uniformly improve conceptual understanding. Structured
integration and complementary instructional strategies are recommended to
foster independent problem-solving skills.

</details>


### [22] [Enhancing Software Testing Education: Understanding Where Students Struggle](https://arxiv.org/abs/2510.00957)
*Shiza Andleeb,Teo Mendoza,Lucas Cordova,Gursimran Walia,Jeffrey C. Carver*

Main category: cs.SE

TL;DR: Analysis of student testing misconceptions in software engineering education, revealing decision coverage and exception handling as major challenges that lead to ineffective test suite revisions.


<details>
  <summary>Details</summary>
Motivation: To identify specific testing concepts that students struggle with and understand how these misunderstandings manifest in unproductive test suite modifications during software testing education.

Method: Analyzed student submissions from two assignments in a senior-level software testing course using an automated feedback tool to identify conceptual gaps and patterns of ineffective modifications.

Result: Found that decision coverage and exception handling are persistent challenges, with students making superficial or method-level changes that fail to improve code coverage.

Conclusion: The findings provide actionable insights for improving feedback systems, targeting instruction to address persistent misconceptions, and better supporting students in developing robust test suites.

Abstract: Effective software testing is critical for producing reliable and secure
software, yet many computer science students struggle to master the
foundational concepts required to construct comprehensive test suites. While
automated feedback tools are widely used to support student learning, it
remains unclear which testing concepts are most frequently misunderstood and
how these misunderstandings are reflected in students' test suite revisions.
This study examines the specific testing concepts that lead students to make
ineffective changes, those that fail to improve code coverage, during test
suite development. Leveraging an automated feedback tool in a senior-level
software testing course, we analyzed student submissions from two assignments
to identify prevalent conceptual gaps and patterns of unproductive
modification. Our results reveal that decision coverage and exception handling
are persistent challenges, and that students most often make superficial or
method-level changes that do not enhance coverage. These findings provide
actionable insights for educators, researchers, and tool designers. By
pinpointing the concepts that most often contribute to poor testing outcomes,
we can refine feedback systems, target instruction to address persistent
misconceptions, and more effectively support students in developing robust,
maintainable test suites.

</details>


### [23] [Semantics-Aligned, Curriculum-Driven, and Reasoning-Enhanced Vulnerability Repair Framework](https://arxiv.org/abs/2510.01002)
*Chengran Yang,Ting Zhang,Jinfeng Jiang,Xin Zhou,Haoye Tian,Jieke Shi,Junkai Chen,Yikun Li,Eng Lieh Ouh,Lwin Khin Shar,David Lo*

Main category: cs.SE

TL;DR: SeCuRepair is a novel vulnerability repair framework that addresses limitations in current learning-based approaches by using explicit reasoning, semantics-aware reinforcement learning, and difficulty-aware curriculum training to improve generalization and handle complex repairs.


<details>
  <summary>Details</summary>
Motivation: Current Automated Vulnerability Repair (AVR) approaches suffer from poor generalization across repositories, inability to handle long-range dependencies in multi-hunk repairs, and over-reliance on superficial lexical patterns that fail with minor syntactic variations.

Method: SeCuRepair uses a reason-then-edit paradigm where models must articulate repair logic before generating patches. It employs semantics-aware reinforcement learning that rewards syntactic and semantic alignment rather than token overlap, and a difficulty-aware curriculum that progresses from simple to complex repairs.

Result: SeCuRepair significantly outperforms all baselines, achieving 34.52% improvement on BigVul and 31.52% on PrimeVul_AVR in terms of CodeBLEU. Comprehensive ablation studies confirm each component contributes to the final performance.

Conclusion: The proposed framework effectively addresses fundamental weaknesses in current AVR approaches through explicit reasoning, semantics-aligned training, and progressive curriculum learning, demonstrating substantial improvements in vulnerability repair performance and generalization.

Abstract: Current learning-based Automated Vulnerability Repair (AVR) approaches, while
promising, often fail to generalize effectively in real-world scenarios. Our
diagnostic analysis reveals three fundamental weaknesses in state-of-the-art
AVR approaches: (1) limited cross-repository generalization, with performance
drops on unseen codebases; (2) inability to capture long-range dependencies,
causing a performance degradation on complex, multi-hunk repairs; and (3)
over-reliance on superficial lexical patterns, leading to significant
performance drops on vulnerabilities with minor syntactic variations like
variable renaming.
  To address these limitations, we propose SeCuRepair, a semantics-aligned,
curriculum-driven, and reasoning-enhanced framework for vulnerability repair.
At its core, SeCuRepair adopts a reason-then-edit paradigm, requiring the model
to articulate why and how a vulnerability should be fixed before generating the
patch. This explicit reasoning enforces a genuine understanding of repair logic
rather than superficial memorization of lexical patterns. SeCuRepair also moves
beyond traditional supervised fine-tuning and employs semantics-aware
reinforcement learning, rewarding patches for their syntactic and semantic
alignment with the oracle patch rather than mere token overlap. Complementing
this, a difficulty-aware curriculum progressively trains the model, starting
with simple fixes and advancing to complex, multi-hunk coordinated edits.
  We evaluate SeCuRepair on strict, repository-level splits of BigVul and newly
crafted PrimeVul_AVR datasets. SeCuRepair significantly outperforms all
baselines, surpassing the best-performing baselines by 34.52% on BigVul and
31.52% on PrimeVul\textsubscript{AVR} in terms of CodeBLEU, respectively.
Comprehensive ablation studies further confirm that each component of our
framework contributes to its final performance.

</details>


### [24] [Improving Code Localization with Repository Memory](https://arxiv.org/abs/2510.01003)
*Boshi Wang,Weijian Xu,Yunsheng Li,Mei Gao,Yujia Xie,Huan Sun,Dongdong Chen*

Main category: cs.SE

TL;DR: Augmenting language agents with repository memory from commit history improves code localization performance on SWE-bench benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing methods handle code localization from scratch without prior repository knowledge, unlike human developers who build long-term memory about functionality and bug-fix associations.

Method: Introduce tools for agents to retrieve from non-parametric memory including recent historical commits, linked issues, and functionality summaries of actively evolving code parts identified via commit patterns.

Result: Significantly improves LocAgent (state-of-the-art localization framework) on both SWE-bench-verified and SWE-bench-live benchmarks.

Conclusion: Repository memory augmentation enables agents to accumulate and leverage past experience for long-horizon tasks, more closely emulating human developer expertise.

Abstract: Code localization is a fundamental challenge in repository-level software
engineering tasks such as bug fixing. While existing methods equip language
agents with comprehensive tools/interfaces to fetch information from the
repository, they overlook the critical aspect of memory, where each instance is
typically handled from scratch assuming no prior repository knowledge. In
contrast, human developers naturally build long-term repository memory, such as
the functionality of key modules and associations between various bug types and
their likely fix locations. In this work, we augment language agents with such
memory by leveraging a repository's commit history - a rich yet underutilized
resource that chronicles the codebase's evolution. We introduce tools that
allow the agent to retrieve from a non-parametric memory encompassing recent
historical commits and linked issues, as well as functionality summaries of
actively evolving parts of the codebase identified via commit patterns. We
demonstrate that augmenting such a memory can significantly improve LocAgent, a
state-of-the-art localization framework, on both SWE-bench-verified and the
more recent SWE-bench-live benchmarks. Our research contributes towards
developing agents that can accumulate and leverage past experience for
long-horizon tasks, more closely emulating the expertise of human developers.

</details>


### [25] [GenIA-E2ETest: A Generative AI-Based Approach for End-to-End Test Automation](https://arxiv.org/abs/2510.01024)
*Elvis J√∫nior,Alan Valejo,Jorge Valverde-Rebaza,V√¢nia de Oliveira Neves*

Main category: cs.SE

TL;DR: GenIA-E2ETest uses generative AI to automatically create executable end-to-end test scripts from natural language descriptions, achieving 77% completeness/correctness, 82% precision, 85% recall with only 10% manual modification.


<details>
  <summary>Details</summary>
Motivation: Manual software testing is time-consuming and error-prone. While LLMs enable automated test generation, existing solutions focus on unit testing and don't address the challenges of end-to-end testing that validates complete application workflows.

Method: Leverages generative AI to automatically generate executable E2E test scripts from natural language descriptions. Evaluated on two web applications assessing completeness, correctness, adaptation effort, and robustness.

Result: Scripts achieved 77% for both element metrics, 82% precision of execution, 85% execution recall, required only 10% manual modification, and showed consistent performance in typical web scenarios. Some sensitivity to context-dependent navigation and dynamic content was observed.

Conclusion: GenIA-E2ETest is a practical and effective solution to accelerate E2E test automation from natural language, reducing manual effort and broadening access to automated testing.

Abstract: Software testing is essential to ensure system quality, but it remains
time-consuming and error-prone when performed manually. Although recent
advances in Large Language Models (LLMs) have enabled automated test
generation, most existing solutions focus on unit testing and do not address
the challenges of end-to-end (E2E) testing, which validates complete
application workflows from user input to final system response. This paper
introduces GenIA-E2ETest, which leverages generative AI to generate executable
E2E test scripts from natural language descriptions automatically. We evaluated
the approach on two web applications, assessing completeness, correctness,
adaptation effort, and robustness. Results were encouraging: the scripts
achieved an average of 77% for both element metrics, 82% for precision of
execution, 85% for execution recall, required minimal manual adjustments
(average manual modification rate of 10%), and showed consistent performance in
typical web scenarios. Although some sensitivity to context-dependent
navigation and dynamic content was observed, the findings suggest that
GenIA-E2ETest is a practical and effective solution to accelerate E2E test
automation from natural language, reducing manual effort and broadening access
to automated testing.

</details>


### [26] [CodeGenLink: A Tool to Find the Likely Origin and License of Automatically Generated Code](https://arxiv.org/abs/2510.01077)
*Daniele Bifolco,Guido Annicchiarico,Pierluigi Barbiero,Massimiliano Di Penta,Fiorella Zampetti*

Main category: cs.SE

TL;DR: CodeGenLink is a GitHub CoPilot extension that helps identify code provenance and licensing information for LLM-generated code by finding similar code snippets online and analyzing their licenses.


<details>
  <summary>Details</summary>
Motivation: Developers are concerned about trustworthiness and potential copyright/licensing violations when using LLM-generated code due to lack of provenance information.

Method: Combines LLMs with web search features to retrieve candidate code links, then performs similarity analysis between generated and retrieved code to filter unrelated links and identify licensing information.

Result: Preliminary results show CodeGenLink effectively filters unrelated links via similarity analysis and provides licensing information when available.

Conclusion: CodeGenLink addresses the trustworthiness and licensing concerns of LLM-generated code by providing provenance information and license identification capabilities.

Abstract: Large Language Models (LLMs) are widely used in software development tasks
nowadays. Unlike reusing code taken from the Web, for LLMs' generated code,
developers are concerned about its lack of trustworthiness and possible
copyright or licensing violations, due to the lack of code provenance
information. This paper proposes CodeGenLink, a GitHub CoPilot extension for
Visual Studio Code aimed at (i) suggesting links containing code very similar
to automatically generated code, and (ii) whenever possible, indicating the
license of the likely origin of the code. CodeGenLink retrieves candidate links
by combining LLMs with their web search features and then performs similarity
analysis between the generated and retrieved code. Preliminary results show
that CodeGenLink effectively filters unrelated links via similarity analysis
and provides licensing information when available. Tool URL:
https://github.com/danielebifolco/CodeGenLink Tool Video:
https://youtu.be/M6nqjBf9_pw

</details>


### [27] [Developers' Perspectives on Software Licensing: Current Practices, Challenges, and Tools](https://arxiv.org/abs/2510.01096)
*Nathan Wintersgill,Trevor Stalnaker,Daniel Otten,Laura A. Heymann,Oscar Chaparro,Massimiliano Di Penta,Daniel M. German,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: Study examines how developers handle open-source license compliance, identifying challenges and tool usage through surveys and interviews.


<details>
  <summary>Details</summary>
Motivation: Understanding developer approaches to license compliance is crucial due to financial, legal, and reputational risks of noncompliance with open-source components.

Method: Mixed-methods study with 58 developer surveys and 7 follow-up interviews conducted by software engineering and legal researchers.

Result: Generated 15 key findings about current licensing practices, challenges, and tool usage in software development.

Conclusion: Provides implications for future research and actionable recommendations for improving licensing tools to support developers.

Abstract: Most modern software products incorporate open-source components, requiring
development teams to maintain compliance with each component's licenses.
Noncompliance can lead to significant financial, legal, and reputational
repercussions. While some organizations may seek advice from legal
practitioners to assist with licensing tasks, developers still play a key role
in such a process. To this end, it is essential to understand how developers
approach license compliance tasks, the challenges they encounter, and the tools
that they use. This work studies these aspects of software licensing practices
through a study - conducted by a joint team of software engineering and legal
researchers - consisting of a survey with 58 software developers and seven
follow-up interviews. The study resulted in 15 key findings regarding the
current state of practice. We discuss the implications of our findings and
offer directions for future research as well as actionable recommendations for
licensing tools.

</details>


### [28] [When Shared Worlds Break: Demystifying Defects in Multi-User Extended Reality Software Systems](https://arxiv.org/abs/2510.01182)
*Shuqing Li,Chenran Zhang,Binchang Li,Cuiyun Gao,Michael R. Lyu*

Main category: cs.SE

TL;DR: First large-scale empirical study of multi-user XR defects analyzing 2,649 real-world bug reports, revealing synchronization and avatar issues as most prevalent problems with severe consequences affecting shared experiences.


<details>
  <summary>Details</summary>
Motivation: Multi-user XR systems introduce unique software defects that compromise user experience, but understanding these defects remains underexplored despite being crucial for enhancing system reliability.

Method: Analyzed 2,649 real-world bug reports from diverse sources (developer forums, GitHub repositories, app reviews) using rigorous qualitative analysis with iterative open coding to develop a comprehensive taxonomy.

Result: Synchronization inconsistencies and avatar-related anomalies are most prevalent symptoms; network/synchronization logic defects and session management flaws are dominant root causes; over 34% of bugs lead to severe consequences that break shared experiences.

Conclusion: Multi-user XR systems face distinct challenges at intersection of distributed systems, real-time 3D interaction, and immersive experiences, requiring specialized approaches to testing, debugging, and quality assurance.

Abstract: Multi-user Extended Reality (XR) systems enable transformative shared
experiences but introduce unique software defects that compromise user
experience. Understanding software defects in multi-user XR systems is crucial
for enhancing system reliability, yet remains underexplored. To fill the gap,
this paper presents the first large-scale empirical study of multi-user XR
defects, analyzing 2,649 real-world bug reports from diverse sources, including
developer forums, GitHub repositories, and app reviews on mainstream XR app
stores. Through rigorous qualitative analysis using iterative open coding, we
develop a comprehensive taxonomy that classifies multi-user XR bugs along three
dimensions: Symptom Manifestation, Root Cause Origin, and Consequence Severity.
Our findings reveal that synchronization inconsistencies and avatar-related
anomalies are the most prevalent symptoms, while network/synchronization logic
defects and session management flaws emerge as dominant root causes.
Critically, over 34% of analyzed bugs lead to severe consequences that
fundamentally break the shared experience, including system crashes, persistent
disconnections, and complete interaction breakdowns, etc. We also identify
concerning privacy and health implications unique to multi-user XR contexts.
Based on our findings of defect analysis, we provide actionable recommendations
for developers, platform vendors, and researchers. Our results demonstrate that
multi-user XR systems face distinct challenges at the intersection of
distributed systems, real-time 3D interaction, and immersive experiences,
necessitating specialized approaches to testing, debugging, and quality
assurance.

</details>
